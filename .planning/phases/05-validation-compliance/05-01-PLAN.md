---
phase: 05-validation-compliance
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/validation_dataset.py
  - tests/annotation_schema.py
  - .planning/phases/05-validation-compliance/datasets/validation_config.json
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Validation dataset loader exists and can ingest real transcripts"
    - "Annotation schema defines PHI entity boundaries in machine-readable format"
    - "Dataset configuration specifies stratified sampling approach"
  artifacts:
    - path: "tests/validation_dataset.py"
      provides: "ValidationHandoff class, load_validation_set function"
      exports: ["ValidationHandoff", "PHIAnnotation", "load_validation_set", "export_for_annotation"]
    - path: "tests/annotation_schema.py"
      provides: "PHI annotation schema compatible with Presidio entity types"
      exports: ["AnnotationSchema", "validate_annotations", "ENTITY_TYPES"]
    - path: ".planning/phases/05-validation-compliance/datasets/validation_config.json"
      provides: "Configuration for validation dataset construction"
      contains: "sample_size"
  key_links:
    - from: "tests/validation_dataset.py"
      to: "tests/annotation_schema.py"
      via: "PHIAnnotation import"
      pattern: "from annotation_schema import"
    - from: "tests/validation_dataset.py"
      to: "tests/generate_test_data.py"
      via: "PHISpan import for compatibility"
      pattern: "from generate_test_data import PHISpan"
---

<objective>
Create validation data pipeline infrastructure for real transcript evaluation

Purpose: External validation requires a different data pipeline than synthetic testing. Real transcripts need annotation, stratified sampling, and format conversion to work with the existing PresidioEvaluator infrastructure.

Output: ValidationHandoff class compatible with existing evaluation infrastructure, annotation schema for human labeling, and dataset configuration for reproducible validation.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-validation-compliance/05-RESEARCH.md
@.planning/phases/05-validation-compliance/05-CONTEXT.md
@tests/evaluate_presidio.py
@tests/generate_test_data.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create annotation schema and validation dataset loader</name>
  <files>
    tests/annotation_schema.py
    tests/validation_dataset.py
  </files>
  <action>
Create tests/annotation_schema.py with:
- ENTITY_TYPES constant matching Presidio entity types (PERSON, PHONE_NUMBER, EMAIL_ADDRESS, DATE_TIME, LOCATION, MEDICAL_RECORD_NUMBER, ROOM, PEDIATRIC_AGE, GUARDIAN_NAME)
- AnnotationSchema dataclass with fields: entity_type, start, end, text, confidence (optional), annotator_id (optional)
- validate_annotations(annotations: list[AnnotationSchema], text: str) function that checks spans are valid (start < end, text matches slice)
- ANNOTATION_GUIDELINES constant with brief per-entity definitions for annotator reference

Create tests/validation_dataset.py with:
- Import PHISpan from generate_test_data: `from tests.generate_test_data import PHISpan`
- PHIAnnotation dataclass (mirrors annotation_schema.AnnotationSchema but adds metadata)
- ValidationHandoff dataclass with fields: id, text, phi_annotations, source (str), transcript_date (optional), annotator_id
- Property `phi_spans` that converts phi_annotations to PHISpan objects:
  ```python
  @property
  def phi_spans(self) -> list[PHISpan]:
      """Convert PHIAnnotation list to PHISpan list for PresidioEvaluator compatibility."""
      return [
          PHISpan(
              entity_type=ann.entity_type,
              start=ann.start,
              end=ann.end,
              text=ann.text
          )
          for ann in self.phi_annotations
      ]
  ```
- load_validation_set(path: Path) function that loads JSON array of ValidationHandoff objects
- export_for_annotation(handoffs: list, output_path: Path) function that exports text-only for manual annotation
- stratified_sample(handoffs: list, n: int, seed: int = 42) function using entity-type distribution stratification

Follow existing patterns from tests/generate_test_data.py for dataclass structure.
  </action>
  <verify>
```bash
python -c "from tests.annotation_schema import ENTITY_TYPES, AnnotationSchema, validate_annotations; print(f'Entity types: {len(ENTITY_TYPES)}')"
python -c "from tests.validation_dataset import ValidationHandoff, load_validation_set, stratified_sample; print('Validation dataset module loaded')"
python -c "
from tests.validation_dataset import ValidationHandoff, PHIAnnotation
from tests.generate_test_data import PHISpan

# Test phi_spans property conversion
h = ValidationHandoff(
    id=1,
    text='Patient John Smith in Room 302',
    phi_annotations=[
        PHIAnnotation(entity_type='PERSON', start=8, end=18, text='John Smith'),
    ],
    source='test'
)
spans = h.phi_spans
assert isinstance(spans[0], PHISpan), 'phi_spans must return PHISpan objects'
print('PHISpan conversion verified')
"
```
  </verify>
  <done>
- annotation_schema.py exports ENTITY_TYPES (9 types), AnnotationSchema class, validate_annotations function
- validation_dataset.py exports ValidationHandoff, load_validation_set, export_for_annotation, stratified_sample
- ValidationHandoff.phi_spans property returns list[PHISpan] compatible with PresidioEvaluator
- PHISpan import from generate_test_data present
  </done>
</task>

<task type="auto">
  <name>Task 2: Create validation dataset configuration</name>
  <files>
    .planning/phases/05-validation-compliance/datasets/validation_config.json
  </files>
  <action>
Create .planning/phases/05-validation-compliance/datasets/ directory and validation_config.json with:
```json
{
  "version": "1.0",
  "created": "[CURRENT_DATE]",
  "config": {
    "target_sample_size": 200,
    "minimum_viable_sample": 50,
    "stratification": {
      "by": "dominant_phi_type",
      "seed": 42
    },
    "train_val_test_split": {
      "train": 0.0,
      "val": 0.7,
      "test": 0.3,
      "note": "No training (using existing model); val for tuning, test for final metrics"
    },
    "annotation": {
      "min_annotators": 1,
      "target_iaa_kappa": 0.8,
      "double_code_percent": 0.2
    }
  },
  "data_sources": {
    "existing_deid": {
      "description": "Pre-existing de-identified transcripts",
      "path": "datasets/real_handoffs/",
      "status": "awaiting_data"
    },
    "irb_prospective": {
      "description": "IRB-approved prospective collection",
      "path": "datasets/irb_handoffs/",
      "status": "pending_irb",
      "irb_protocol": null
    }
  },
  "entity_type_targets": {
    "PERSON": 100,
    "PHONE_NUMBER": 30,
    "DATE_TIME": 200,
    "LOCATION": 50,
    "MEDICAL_RECORD_NUMBER": 80,
    "ROOM": 100,
    "PEDIATRIC_AGE": 80,
    "GUARDIAN_NAME": 60
  }
}
```

Also create empty placeholder directories:
- .planning/phases/05-validation-compliance/datasets/real_handoffs/ (with .gitkeep)
- .planning/phases/05-validation-compliance/datasets/annotated/ (with .gitkeep)
  </action>
  <verify>
```bash
cat ".planning/phases/05-validation-compliance/datasets/validation_config.json" | python -c "import json,sys; c=json.load(sys.stdin); print(f'Target sample: {c[\"config\"][\"target_sample_size\"]}')"
ls -la ".planning/phases/05-validation-compliance/datasets/"
```
  </verify>
  <done>
- validation_config.json exists with sample_size=200, stratification config, train/val/test split
- datasets/ directory structure created with placeholders for real data
- Entity type targets documented for coverage tracking
  </done>
</task>

</tasks>

<verification>
1. Run module imports to verify no syntax errors
2. Check validation_config.json is valid JSON
3. Verify ValidationHandoff.phi_spans returns PHISpan-compatible objects

```bash
cd "/Users/joshpankin/My Drive/10-19 Projects/12 Development & AI Projects/12.09 Pediatric_Handoff_PHI_Remover"
python -c "
from tests.validation_dataset import ValidationHandoff, PHIAnnotation
from tests.annotation_schema import AnnotationSchema, ENTITY_TYPES
from tests.generate_test_data import PHISpan

# Test compatibility
h = ValidationHandoff(
    id=1,
    text='Patient John Smith in Room 302',
    phi_annotations=[
        PHIAnnotation(entity_type='PERSON', start=8, end=18, text='John Smith'),
        PHIAnnotation(entity_type='ROOM', start=22, end=30, text='Room 302')
    ],
    source='test'
)
spans = h.phi_spans
assert all(isinstance(s, PHISpan) for s in spans), 'All spans must be PHISpan instances'
print(f'ValidationHandoff created with {len(spans)} PHISpan objects')
print(f'Entity types defined: {len(ENTITY_TYPES)}')
print('Pipeline ready for validation data ingestion')
"
```
</verification>

<success_criteria>
- [ ] tests/annotation_schema.py imports without error
- [ ] tests/validation_dataset.py imports without error
- [ ] ValidationHandoff.phi_spans returns list[PHISpan] (not just compatible objects)
- [ ] PHISpan import from generate_test_data verified
- [ ] validation_config.json is valid JSON with target_sample_size
- [ ] Dataset directory structure created
</success_criteria>

<output>
After completion, create `.planning/phases/05-validation-compliance/05-01-SUMMARY.md`
</output>

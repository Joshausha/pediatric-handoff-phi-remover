# Plan: Add Weighted Scoring to evaluate_presidio.py

**Phase**: 8 - Weighted Recall Evaluation
**Plan**: 08-01-PLAN.md
**Status**: Ready
**Created**: 2026-01-25

## Objective

Implement spoken handoff relevance weighting in evaluate_presidio.py so metrics reflect real-world clinical importance rather than treating all PHI types equally.

## Background

Per SPOKEN_HANDOFF_ANALYSIS.md:
- Unweighted recall (77.9%) underestimates performance for spoken handoffs
- Weighted recall (91.5%) reflects actual clinical relevance
- Some PHI types (addresses, email) are never spoken during handoffs

## Weight Definitions

From SPOKEN_HANDOFF_ANALYSIS.md methodology:

| Entity | Weight | Rationale |
|--------|--------|-----------|
| PERSON | 5 | Critical - spoken constantly |
| ROOM | 4 | High - used for patient identification |
| PHONE_NUMBER | 2 | Medium - occasionally spoken |
| DATE_TIME | 2 | Medium - admission dates, but often vague |
| MRN | 1 | Low - rarely spoken aloud |
| EMAIL_ADDRESS | 0 | Never spoken |
| LOCATION | 0 | Never spoken - addresses not relevant |
| PEDIATRIC_AGE | 0 | User decision - ages not PHI under HIPAA |

## Tasks

### Wave 1: Configuration

#### Task 1.1: Add weight configuration to config.py

Add new settings to `app/config.py`:

```python
# Spoken handoff relevance weights (for weighted recall calculation)
# Higher weight = more frequently spoken during I-PASS handoffs
spoken_handoff_weights: dict[str, int] = {
    "PERSON": 5,
    "GUARDIAN_NAME": 5,  # Same as PERSON
    "ROOM": 4,
    "PHONE_NUMBER": 2,
    "DATE_TIME": 2,
    "MEDICAL_RECORD_NUMBER": 1,
    "EMAIL_ADDRESS": 0,
    "LOCATION": 0,
    "PEDIATRIC_AGE": 0,
}
```

### Wave 2: Evaluation Script Changes

#### Task 2.1: Add weighted metrics to EvaluationMetrics class

Extend `tests/evaluate_presidio.py` EvaluationMetrics class:

```python
@dataclass
class EvaluationMetrics:
    # ... existing fields ...

    # Per-entity type tracking for weighted calculation
    entity_stats: dict[str, dict[str, int]] = field(default_factory=dict)

    def weighted_recall(self, weights: dict[str, int]) -> float:
        """Calculate recall weighted by spoken handoff relevance."""
        weighted_tp = 0
        weighted_total = 0
        for entity_type, stats in self.entity_stats.items():
            weight = weights.get(entity_type, 0)
            weighted_tp += stats["tp"] * weight
            weighted_total += (stats["tp"] + stats["fn"]) * weight
        return weighted_tp / weighted_total if weighted_total > 0 else 0.0

    def weighted_precision(self, weights: dict[str, int]) -> float:
        """Calculate precision weighted by spoken handoff relevance."""
        weighted_tp = 0
        weighted_detected = 0
        for entity_type, stats in self.entity_stats.items():
            weight = weights.get(entity_type, 0)
            weighted_tp += stats["tp"] * weight
            weighted_detected += (stats["tp"] + stats["fp"]) * weight
        return weighted_tp / weighted_detected if weighted_detected > 0 else 0.0

    def weighted_f2(self, weights: dict[str, int]) -> float:
        """Calculate F2 score weighted by spoken handoff relevance."""
        p = self.weighted_precision(weights)
        r = self.weighted_recall(weights)
        beta = 2.0
        if p + r == 0:
            return 0.0
        return (1 + beta**2) * (p * r) / (beta**2 * p + r)
```

#### Task 2.2: Track per-entity stats during evaluation

Modify `evaluate_dataset()` to populate `entity_stats` dict:

```python
def evaluate_dataset(self, dataset, verbose=False):
    # ... existing code ...

    # Initialize entity stats tracking
    entity_stats = {}

    for result in results:
        for span in result.true_positives:
            entity_stats.setdefault(span.entity_type, {"tp": 0, "fn": 0, "fp": 0})
            entity_stats[span.entity_type]["tp"] += 1
        for span in result.false_negatives:
            entity_stats.setdefault(span.entity_type, {"tp": 0, "fn": 0, "fp": 0})
            entity_stats[span.entity_type]["fn"] += 1
        for det in result.false_positives:
            entity_stats.setdefault(det["entity_type"], {"tp": 0, "fn": 0, "fp": 0})
            entity_stats[det["entity_type"]]["fp"] += 1

    metrics.entity_stats = entity_stats
    return metrics, results
```

#### Task 2.3: Add --weighted CLI flag

Add argument to main():

```python
parser.add_argument(
    "--weighted",
    action="store_true",
    help="Report weighted metrics using spoken handoff relevance weights"
)
```

#### Task 2.4: Update report generation

Modify `generate_report()` to include weighted metrics when requested:

```python
def generate_report(self, metrics, results, show_failures=True, weighted=False):
    # ... existing lines ...

    if weighted:
        from app.config import settings
        weights = settings.spoken_handoff_weights

        lines.append("")
        lines.append("WEIGHTED METRICS (spoken handoff relevance):")
        lines.append(f"  Weighted Recall:    {metrics.weighted_recall(weights):.1%}")
        lines.append(f"  Weighted Precision: {metrics.weighted_precision(weights):.1%}")
        lines.append(f"  Weighted F2 Score:  {metrics.weighted_f2(weights):.1%}  ← PRIMARY METRIC")
        lines.append("")
        lines.append("  Weights applied:")
        for entity, weight in sorted(weights.items(), key=lambda x: -x[1]):
            lines.append(f"    {entity}: {weight}")
```

### Wave 3: Validation

#### Task 3.1: Add validation test

Create test that verifies weighted calculations match SPOKEN_HANDOFF_ANALYSIS.md:

```python
def test_weighted_metrics_match_analysis():
    """Verify weighted calculations match manual verification in docs."""
    # From SPOKEN_HANDOFF_ANALYSIS.md appendix
    entity_stats = {
        "PERSON": {"tp": 747, "fn": 9, "fp": 79},
        "ROOM": {"tp": 31, "fn": 59, "fp": 24},
        "PHONE_NUMBER": {"tp": 142, "fn": 50, "fp": 1},
        "DATE_TIME": {"tp": 184, "fn": 6, "fp": 334},
        "MEDICAL_RECORD_NUMBER": {"tp": 90, "fn": 37, "fp": 12},
        "EMAIL_ADDRESS": {"tp": 24, "fn": 0, "fp": 0},
        "LOCATION": {"tp": 25, "fn": 104, "fp": 6},
        "PEDIATRIC_AGE": {"tp": 60, "fn": 104, "fp": 9},
    }

    weights = {
        "PERSON": 5, "GUARDIAN_NAME": 5,
        "ROOM": 4, "PHONE_NUMBER": 2, "DATE_TIME": 2,
        "MEDICAL_RECORD_NUMBER": 1,
        "EMAIL_ADDRESS": 0, "LOCATION": 0, "PEDIATRIC_AGE": 0,
    }

    # Calculate weighted recall
    weighted_tp = sum(stats["tp"] * weights.get(e, 0) for e, stats in entity_stats.items())
    weighted_total = sum((stats["tp"] + stats["fn"]) * weights.get(e, 0) for e, stats in entity_stats.items())

    assert abs(weighted_tp / weighted_total - 0.915) < 0.01  # ~91.5%
```

## Success Criteria

1. `python tests/evaluate_presidio.py --weighted` shows both unweighted and weighted metrics
2. Weighted recall matches ~91.5% (within rounding) on current synthetic dataset
3. Weights are configurable in config.py for future adjustment
4. No changes to existing unweighted behavior (backward compatible)

## Files Modified

- `app/config.py` - Add spoken_handoff_weights setting
- `tests/evaluate_presidio.py` - Add weighted metrics support
- `tests/test_evaluation.py` (new or existing) - Validation tests

## Verification

```bash
# Run evaluation with weighted metrics
python tests/evaluate_presidio.py --weighted -v

# Expected output includes:
# WEIGHTED METRICS (spoken handoff relevance):
#   Weighted Recall:    91.5%
#   Weighted Precision: 79.7%
#   Weighted F2 Score:  88.8%  ← PRIMARY METRIC
```

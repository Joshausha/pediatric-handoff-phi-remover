---
phase: 07-alternative-engine-benchmark
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/benchmark_philter.py
  - configs/philter_pediatric.json
  - patterns/guardian_patterns.txt
  - patterns/room_patterns.txt
  - requirements.txt
autonomous: true

must_haves:
  truths:
    - "Philter-UCSF is installed and importable"
    - "Pediatric patterns are translated to Philter config format"
    - "Philter can analyze handoff text and return PHI spans"
    - "Lookbehind pattern support is documented in script comments"
  artifacts:
    - path: "scripts/benchmark_philter.py"
      provides: "Philter benchmarking script"
      min_lines: 100
    - path: "configs/philter_pediatric.json"
      provides: "Philter pattern configuration"
      contains: "guardian"
    - path: "patterns/guardian_patterns.txt"
      provides: "Guardian name regex patterns for Philter"
      min_lines: 3
    - path: "patterns/room_patterns.txt"
      provides: "Room number regex patterns for Philter"
      min_lines: 2
  key_links:
    - from: "scripts/benchmark_philter.py"
      to: "configs/philter_pediatric.json"
      via: "config file path"
      pattern: "philter_pediatric.json"
    - from: "scripts/benchmark_philter.py"
      to: "tests/synthetic_handoffs.json"
      via: "dataset loading"
      pattern: 'data\["handoffs"\]'
---

<objective>
Install Philter-UCSF and translate current pediatric/medical patterns to Philter configuration format.

Purpose: Enable fair comparison of Philter's rule-based de-identification against current Presidio setup on spoken handoff data.

Output: Working Philter installation with pediatric pattern configuration and benchmarking script.
</objective>

<execution_context>
@/Users/joshpankin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/joshpankin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-alternative-engine-benchmark/07-RESEARCH.md
@.planning/phases/07-alternative-engine-benchmark/07-CONTEXT.md
@app/recognizers/pediatric.py
@app/recognizers/medical.py
@tests/evaluate_presidio.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Philter-UCSF and test lookbehind support</name>
  <files>requirements.txt</files>
  <action>
1. Add philter-ucsf to requirements.txt
2. Install with pip: `pip install philter-ucsf`
3. Test lookbehind pattern support with simple pattern:
   - Create test pattern: `(?<=mom )\w+`
   - Run on sample text: "mom jessica brought baby smith"
   - Document result: either pattern matches "jessica" or fails
4. If lookbehind fails, test alternative approach:
   - Rewrite pattern as: `\b(?:mom)\s+(\w+)\b` (capture group)
   - Document which approach works for pattern translation
5. Document lookbehind test results in a docstring at the top of benchmark_philter.py (Task 2)

CRITICAL: This determines pattern translation strategy for Task 2. If lookbehind not supported, all patterns must be rewritten.
  </action>
  <verify>
```bash
python -c "from philter_ucsf import Philter; print('Philter imported successfully')"
```
Lookbehind test result documented in script comments.
  </verify>
  <done>Philter-UCSF installed, lookbehind support status documented with working pattern approach.</done>
</task>

<task type="auto">
  <name>Task 2: Create Philter pattern configuration and benchmark script</name>
  <files>configs/philter_pediatric.json, patterns/guardian_patterns.txt, patterns/room_patterns.txt, scripts/benchmark_philter.py</files>
  <action>
1. **Create directories first:**
   ```bash
   mkdir -p configs patterns scripts
   ```

2. Create pattern files for Philter (one regex per line):
   - `patterns/guardian_patterns.txt`: Translate patterns from pediatric.py (GuardianNameRecognizer)
     - mom/dad/mother/father + name patterns
     - Use format that works from Task 1 (lookbehind or capture group)
   - `patterns/room_patterns.txt`: Translate from medical.py (RoomRecognizer)
     - room/bed/bay patterns with unit names

3. Create `configs/philter_pediatric.json`:
   ```json
   {
     "patterns": [
       {
         "title": "guardian_names",
         "type": "regex",
         "filepath": "./patterns/guardian_patterns.txt",
         "exclude": true,
         "phi_type": "GUARDIAN_NAME"
       },
       {
         "title": "room_numbers",
         "type": "regex",
         "filepath": "./patterns/room_patterns.txt",
         "exclude": true,
         "phi_type": "ROOM"
       }
     ]
   }
   ```

4. Create `scripts/benchmark_philter.py`:
   - **Import EvaluationMetrics correctly:**
     ```python
     import sys
     sys.path.insert(0, str(Path(__file__).parent.parent))
     from tests.evaluate_presidio import EvaluationMetrics, DetectionResult
     ```
   - **Load dataset correctly (dict with "handoffs" key):**
     ```python
     with open(input_path) as f:
         data = json.load(f)
     handoffs = data["handoffs"]  # NOT data directly - it's a dict
     ```
   - Run Philter on each handoff text
   - Compare Philter PHI spans against ground truth (same logic as evaluate_presidio.py)
   - Calculate precision, recall, F2, weighted metrics
   - Output report in same format as Presidio evaluator
   - Include --weighted flag for spoken handoff weights

5. Document lookbehind support status in docstring at top of script:
   ```python
   """
   Philter-UCSF benchmark script.

   LOOKBEHIND SUPPORT: [Document result from Task 1]
   - If supported: Using lookbehind patterns (?<=mom )\\w+
   - If not supported: Using capture groups \\b(?:mom)\\s+(\\w+)\\b
   """
   ```

NOTE: Focus on high-weight patterns (GUARDIAN_NAME weight=5, ROOM weight=4). Skip MRN (weight=1) and PEDIATRIC_AGE (disabled).
  </action>
  <verify>
```bash
# Run Philter benchmark on small sample
python scripts/benchmark_philter.py --input tests/synthetic_handoffs.json --verbose | head -50
```
Script runs without errors and produces metrics output.
  </verify>
  <done>Philter pattern config complete, benchmark script produces precision/recall/F2 metrics matching format of Presidio evaluator.</done>
</task>

</tasks>

<verification>
1. `pip show philter-ucsf` shows installed version
2. `python -c "from philter_ucsf import Philter"` succeeds
3. Directories exist: `ls configs/ patterns/ scripts/`
4. `python scripts/benchmark_philter.py --input tests/synthetic_handoffs.json` runs and outputs metrics
5. Pattern files exist: `configs/philter_pediatric.json`, `patterns/*.txt`
6. Script loads dataset as `data["handoffs"]`, not as raw list
</verification>

<success_criteria>
- Philter-UCSF installed and importable
- Pediatric patterns translated to Philter format with documented approach (lookbehind or alternative)
- Benchmark script runs on synthetic dataset and produces comparable metrics to Presidio evaluator
- EvaluationMetrics imported from tests/evaluate_presidio.py (not duplicated)
- Dataset accessed via data["handoffs"] key
- Ready for comparative benchmark in 07-03
</success_criteria>

<output>
After completion, create `.planning/phases/07-alternative-engine-benchmark/07-01-SUMMARY.md`
</output>
